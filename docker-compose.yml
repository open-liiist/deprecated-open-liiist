services:

  web-client:
    build: 
      context: ./web-client
      target: dev
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    volumes:
      # Mount the web-client directory to the container (live reloading)
      - ./web-client:/app
      # host node_modules
      - /app/node_modules
      - /app/.next
    command: npm run dev
    environment:
      - NODE_ENV=${NODE_ENV}
      - LOG_LEVEL=${LOG_LEVEL}
      - API_BASE_URL=${API_BASE_URL}
      - NAME_COOKIE_ACCESS=${NAME_COOKIE_ACCESS}
      - NAME_COOKIE_REFRESH=${NAME_COOKIE_REFRESH}

  auth-service:
    build: 
      context: ./auth-service
      dockerfile: Dockerfile
    ports:
      - "4000:4000"
    depends_on:
      db:
        condition: service_healthy
    environment:
      - AUTH_SERVICE_PORT=${AUTH_SERVICE_PORT}
      - AUTH_DATABASE_URL=${AUTH_DATABASE_URL}
      - ACCESS_TOKEN_SECRET=${ACCESS_TOKEN_SECRET}
      - REFRESH_TOKEN_SECRET=${REFRESH_TOKEN_SECRET}

  search-service:
    build: 
      context: ./search-service
      dockerfile: Dockerfile
    ports:
      - "4001:4001"
    # depends_on:
    #   db:
    #     condition: service_healthy
    environment:
      - SEARCH_SERVICE_PORT=${SEARCH_SERVICE_PORT}
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - REMOTE_DATABASE_URL=${REMOTE_DATABASE_URL}  # Add: to point to the remote DB
      - RUST_LOG=debug  #log: DEBUG



  product-receiver-service:
    container_name: product-receiver-service
    build: 
      context: ./product-receiver-service
      dockerfile: Dockerfile
    # depends_on:
    #  db: 
    #      condition: service_healthy
    ports:
      - "3002:3002"
    environment:
      - PRODUCT_RECEIVER_SERVICE_PORT=${PRODUCT_RECEIVER_SERVICE_PORT}
      - REMOTE_DATABASE_URL=${REMOTE_DATABASE_URL}
    #  - DATABASE_URL=${DATABASE_URL} <- This is not needed with a remote database
      - LOGSTASH_HOST=logstash
      - LOGSTASH_PORT=50000
    volumes:
      - ./product-receiver-service:/app
      - product_receiver_data:/app/data

  db:
    image: postgres:13
    restart: always
    ports:
      - "5432:5432"
    environment:
      PGUSER: user
      POSTGRES_USER: user
      POSTGRES_PASSWORD: postgrespw
      POSTGRES_DB: appdb
    healthcheck:
      test: "pg_isready -h db"
      interval: 10s
      timeout: 10s
      retries: 10
    volumes:
      - pgdata:/var/lib/postgresql/data

  adminer:
    image: adminer
    restart: always
    command: php -S [::]:8090 -t /var/www/html
    ports:
      - 8090:8090

  uptime-kuma:
    image: louislam/uptime-kuma:1
    restart: unless-stopped
    network_mode: host
    ports:
      - 3003:3003
    volumes:
      - ./data:/app/data
    environment:
      - UPTIME_KUMA_PORT=${UPTIME_KUMA_PORT}

  traefik:
    image: docker.io/library/traefik:v3.1.6
    container_name: traefik
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
      # enable dashboard, don't do in production
      - "8080:8080"
    volumes:
      - /run/docker.sock:/run/docker.sock:ro #For Linux
    #  - /var/run/docker.sock:/var/run/docker.sock:ro #For MacOs
      - ./config/traefik.yml:/etc/traefik/traefik.yml:ro
      - ./config/conf.d/:/etc/traefik/conf.d/:ro
      - ./certs/:/var/traefik/certs/:rw

  elasticsearch:
    build:
      context: elasticsearch/
      dockerfile: Dockerfile
      args: 
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro,Z
      - ./elasticsearch/setup-elasticsearch.sh:/usr/share/elasticsearch/setup-elasticsearch.sh
      - elasticsearch:/usr/share/elasticsearch/data:Z
    entrypoint: |
      sh -c "
        elasticsearch &
        chmod +x /usr/share/elasticsearch/setup-elasticsearch.sh &&
        sleep 10 &&
        /usr/share/elasticsearch/setup-elasticsearch.sh &&
        wait
      "
    environment:
      node.name: elasticsearch
      #ES_JAVA_OPTS: -Xms512m -Xmx512m 
      ES_JAVA_OPTS: "-Xms1g -Xmx1g"

      discovery.type: single-node
      ELASTIC_PASSWORD: ${ELASTIC_PASSWORD:-}
    restart: unless-stopped

  logstash:
    build:
      context: logstash/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    volumes:
      - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:rw,Z
      - ./logstash/pipeline:/usr/share/logstash/pipeline:rw,Z
      - logstash_data:/usr/share/logstash/data

    ports:
      - 5044:5044
      - 50000:50000/tcp
      - 50000:50000/udp
      - 9600:9600
    environment:
      LS_JAVA_OPTS: -Xmx256m -Xms256m
      LOGSTASH_INTERNAL_PASSWORD: ${LOGSTASH_INTERNAL_PASSWORD:-}
    depends_on:
      - elasticsearch
    restart: unless-stopped

  kibana:
    build:
      context: kibana/
      args:
        ELASTIC_VERSION: ${ELASTIC_VERSION}
    ports:
      - "5601:5601"
    volumes:
      - ./kibana/config/kibana.yml:/usr/share/kibana/config/kibana.yml:ro,Z
      - kibana_data:/usr/share/kibana/data

    environment:
      KIBANA_SYSTEM_PASSWORD: ${KIBANA_SYSTEM_PASSWORD:-}
    depends_on:
      - elasticsearch
    restart: unless-stopped

  notification-alert:
    build: ./notification-alert
    ports:
      - "5000:5000"


# this part is commented because it will not be needed during the presentation
  # services:
  #   scraping-conad:
  #     user: root
  #     build:
  #       context: ./scraping-service/scraping/conad
  #       dockerfile: ../../../Dockerfile.scraping_conad
  #     container_name: scraping-conad
  #     volumes:
  #       - /var/run/docker.sock:/var/run/docker.sock
  #       - ./scraping-service/scraping/conad:/app
  #     depends_on:
  #       - db
  #       - product-receiver-service
  #       - notification-alert
  #     stop_grace_period: 30s
  #     restart: unless-stopped

  #   scraping-gros-groups:
  #     user: root
  #     build:
  #       context: ./scraping-service/scraping/gros_groups
  #       dockerfile: ../../../Dockerfile.scraping_gros_groups
  #     container_name: scraping-gros-groups
  #     volumes:
  #       - /var/run/docker.sock:/var/run/docker.sock
  #       - ./scraping-service/scraping/gros_groups:/app
  #     depends_on:
  #       - db
  #       - product-receiver-service
  #       - notification-alert
  #     stop_grace_period: 30s
  #     restart: unless-stopped

  #   scraping-oasi-tigre:
  #     user: root
  #     build:
  #       context: ./scraping-service/scraping/oasi_tigre
  #       dockerfile: ../../../Dockerfile.scraping_oasi_tigre
  #     container_name: scraping-oasi-tigre
  #     volumes:
  #       - /var/run/docker.sock:/var/run/docker.sock
  #       - ./scraping-service/scraping/oasi_tigre:/app
  #     depends_on:
  #       - db
  #       - product-receiver-service
  #       - notification-alert
  #     stop_grace_period: 30s
  #     restart: unless-stopped

  #   scraping-shop:
  #     user: root
  #     build:
  #       context: ./scraping-service/scraping_shop
  #       dockerfile: ../../../Dockerfile.scraping_shop
  #     container_name: scraping-shop
  #     volumes:
  #       - /var/run/docker.sock:/var/run/docker.sock
  #       - ./scraping-service/scraping_shop:/app
  #       - ./.env:/app/.env
  #     depends_on:
  #       - db
  #       - product-receiver-service
  #       - notification-alert
  #     stop_grace_period: 30s
  #     restart: unless-stopped

volumes:
  pgdata: 
  elasticsearch:
  kibana_data:
  logstash_data:
  product_receiver_data:

networks:
  shared-network:
    external: true